import streamlit as st
import json
import re
import time
import textwrap

import spacy
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
import google.generativeai as genai

genai.configure(api_key="xxxxxx")
model = genai.GenerativeModel("gemini-2.0-flash")


@st.cache_resource
def load_ner_pipelines():
    pipes = {}

    pipes["English"] = spacy.load("en_core_web_lg")

    hi_tok = AutoTokenizer.from_pretrained("ai4bharat/IndicNER")
    hi_mod = AutoModelForTokenClassification.from_pretrained(
        "ai4bharat/IndicNER")
    pipes["Hindi"] = pipeline(
        "ner", model=hi_mod, tokenizer=hi_tok, aggregation_strategy="simple"
    )

    ur_tok = AutoTokenizer.from_pretrained("mirfan899/urdu-bert-ner")
    ur_mod = AutoModelForTokenClassification.from_pretrained(
        "mirfan899/urdu-bert-ner")
    pipes["Urdu"] = pipeline(
        "ner", model=ur_mod, tokenizer=ur_tok, aggregation_strategy="simple"
    )
    ar_tok = AutoTokenizer.from_pretrained(
        "CAMeL-Lab/bert-base-arabic-camelbert-mix-ner"
    )
    ar_mod = AutoModelForTokenClassification.from_pretrained(
        "CAMeL-Lab/bert-base-arabic-camelbert-mix-ner"
    )
    pipes["Arabic"] = pipeline(
        "ner", model=ar_mod, tokenizer=ar_tok, aggregation_strategy="simple"
    )

    return pipes


def build_label_prompt(lang: str, text: str, entities: list[str]) -> str:
    entity_list = json.dumps(entities, ensure_ascii=False)
    if lang == "English":
        return f"""
You are a narrative understanding assistant.

Given the following text and list of entities, assign each entity one of:
 - Protagonist
 - Antagonist
 - Neutral

Reply ONLY with valid JSON (no explanation), e.g.:

[
  {{ "entity": "Entity Name", "label": "Protagonist" }},
  ...
]

Text: {text}

Entities: {entity_list}
"""
    if lang == "Hindi":
        return f"""
à¤†à¤ª à¤à¤• narrative understanding à¤¸à¤¹à¤¾à¤¯à¤• à¤¹à¥ˆà¤‚à¥¤

à¤¨à¤¿à¤®à¥à¤¨à¤²à¤¿à¤–à¤¿à¤¤ à¤¸à¤®à¤¾à¤šà¤¾à¤° à¤ªà¤¾à¤  à¤”à¤° à¤¸à¤‚à¤¸à¥à¤¥à¤¾à¤“à¤‚ à¤•à¥€ à¤¸à¥‚à¤šà¥€ à¤•à¥‡ à¤†à¤§à¤¾à¤° à¤ªà¤° à¤ªà¥à¤°à¤¤à¥à¤¯à¥‡à¤• à¤¸à¤‚à¤¸à¥à¤¥à¤¾ à¤•à¥‹ à¤à¤• à¤­à¥‚à¤®à¤¿à¤•à¤¾ à¤¦à¥‡à¤‚:
- Protagonist
- Antagonist
- Neutral

à¤•à¥‡à¤µà¤² à¤®à¤¾à¤¨à¥à¤¯ JSON à¤®à¥‡à¤‚ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥‡à¤‚, à¤•à¥‹à¤ˆ à¤µà¥à¤¯à¤¾à¤–à¥à¤¯à¤¾ à¤¨à¤¹à¥€à¤‚à¥¤ à¤‰à¤¦à¤¾à¤¹à¤°à¤£:
[
  {{ "entity": "à¤¸à¤‚à¤¸à¥à¤¥à¤¾ à¤•à¤¾ à¤¨à¤¾à¤®", "label": "Protagonist" }},
  ...
]

à¤¸à¤®à¤¾à¤šà¤¾à¤°: {text}

à¤¸à¤‚à¤¸à¥à¤¥à¤¾à¤à¤‚: {entity_list}
"""
    if lang == "Urdu":
        return f"""
Ø¢Ù¾ Ø§ÛŒÚ© Ø¨ÛŒØ§Ù†ÛŒÛ ÙÛÙ…ÛŒ Ø§Ø³Ø³Ù¹Ù†Ù¹ ÛÛŒÚºÛ”

Ù…Ù†Ø¯Ø±Ø¬Û Ø°ÛŒÙ„ Ø®Ø¨Ø± Ø§ÙˆØ± Ø§Ø¯Ø§Ø±ÙˆÚº Ú©ÛŒ ÙÛØ±Ø³Øª Ú©ÛŒ Ø¨Ù†ÛŒØ§Ø¯ Ù¾Ø± ÛØ± Ø§Ø¯Ø§Ø±Û’ Ú©Ùˆ Ø§ÛŒÚ© Ú©Ø±Ø¯Ø§Ø± ØªÙÙˆÛŒØ¶ Ú©Ø±ÛŒÚº:
- Protagonist
- Antagonist
- Neutral

ØµØ±Ù ØµØ­ÛŒØ­ JSON Ù…ÛŒÚº Ø¬ÙˆØ§Ø¨ Ø¯ÛŒÚºØŒ Ú©ÙˆØ¦ÛŒ ÙˆØ¶Ø§Ø­Øª Ù†ÛÛŒÚº:
[
  {{ "entity": "Ø§Ø¯Ø§Ø±Û’ Ú©Ø§ Ù†Ø§Ù…", "label": "Protagonist" }},
  ...
]

Ø®Ø¨Ø±: {text}

Ø§Ø¯Ø§Ø±Û’: {entity_list}
"""
    if lang == "Arabic":
        return f"""
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù„ÙÙ‡Ù… Ø§Ù„Ø³Ø±Ø¯.

Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆÙ‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙŠØ§Ù†Ø§ØªØŒ ØµÙ†Ù ÙƒÙ„ ÙƒÙŠØ§Ù† Ø¥Ù„Ù‰:
- Protagonist
- Antagonist
- Neutral

Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø¨ØµÙŠØºØ© JSON ØµØ§Ù„Ø­Ø©ØŒ Ø¯ÙˆÙ† Ø´Ø±Ø­. Ù…Ø«Ø§Ù„:
[
  {{ "entity": "Ø§Ø³Ù… Ø§Ù„ÙƒÙŠØ§Ù†", "label": "Protagonist" }},
  ...
]

Ø§Ù„Ù†Øµ: {text}

Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª: {entity_list}
"""
    raise ValueError(f"Unsupported language: {lang}")


def build_narrative_prompt(lang: str, text: str, entities: list[str]) -> str:
    entity_list = json.dumps(entities, ensure_ascii=False)
    if lang == "English":
        return f"""
You are a narrative extraction assistant.

From the text below, extract all complete events.  
Each event must have:
- subject (choose only from the entities list)
- action (verb)
- object (choose only from the entities list)
- context (optional extra details)

Reply ONLY with a JSON array of objects, e.g.:
[
  {{
    "subject": "...",
    "action": "...",
    "object": "...",
    "context": "..."
  }}
]

Text: {text}

Entities: {entity_list}
"""
    if lang == "Hindi":
        return f"""
à¤†à¤ª à¤à¤• narrative extraction à¤¸à¤¹à¤¾à¤¯à¤• à¤¹à¥ˆà¤‚à¥¤

à¤¨à¥€à¤šà¥‡ à¤¦à¤¿à¤ à¤ªà¤¾à¤  à¤¸à¥‡ à¤¸à¤­à¥€ à¤˜à¤Ÿà¤¨à¤¾à¤à¤ à¤¨à¤¿à¤•à¤¾à¤²à¥‡à¤‚:
- subject (à¤¸à¤‚à¤¸à¥à¤¥à¤¾à¤“à¤‚ à¤¸à¥‡ à¤šà¥à¤¨à¥‡à¤‚)
- action (à¤•à¥à¤°à¤¿à¤¯à¤¾)
- object (à¤¸à¤‚à¤¸à¥à¤¥à¤¾à¤“à¤‚ à¤¸à¥‡ à¤šà¥à¤¨à¥‡à¤‚)
- context (à¤µà¥ˆà¤•à¤²à¥à¤ªà¤¿à¤• à¤µà¤¿à¤µà¤°à¤£)

à¤•à¥‡à¤µà¤² JSON à¤¸à¥‚à¤šà¥€ à¤µà¤¾à¤ªà¤¸ à¤•à¤°à¥‡à¤‚, à¤•à¥‹à¤ˆ à¤µà¤¿à¤µà¤°à¤£ à¤¨à¤¹à¥€à¤‚:

à¤¸à¤®à¤¾à¤šà¤¾à¤°: {text}

à¤¸à¤‚à¤¸à¥à¤¥à¤¾à¤à¤‚: {entity_list}
"""
    if lang == "Urdu":
        return f"""
Ø¢Ù¾ Ø§ÛŒÚ© Ø¨ÛŒØ§Ù†ÛŒÛ Ù†Ú©Ø§Ù„Ù†Û’ ÙˆØ§Ù„Û’ Ø§Ø³Ø³Ù¹Ù†Ù¹ ÛÛŒÚºÛ”

Ù…Ù†Ø¯Ø±Ø¬Û Ø°ÛŒÙ„ Ø®Ø¨Ø± Ø³Û’ ØªÙ…Ø§Ù… Ù…Ú©Ù…Ù„ ÙˆØ§Ù‚Ø¹Ø§Øª Ù†Ú©Ø§Ù„ÛŒÚº:
- subject (Ø§Ø¯Ø§Ø±ÙˆÚº Ù…ÛŒÚº Ø³Û’ Ú†Ù†ÛŒÚº)
- action (Ú©ÛŒØ§ Ú©ÛŒØ§)
- object (Ø§Ø¯Ø§Ø±ÙˆÚº Ù…ÛŒÚº Ø³Û’ Ú†Ù†ÛŒÚº)
- context (Ø§Ø®ØªÛŒØ§Ø±ÛŒ Ø§Ø¶Ø§ÙÛŒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª)

ØµØ±Ù JSON ÙÛØ±Ø³Øª ÙˆØ§Ù¾Ø³ Ú©Ø±ÛŒÚºØŒ Ú©ÙˆØ¦ÛŒ ÙˆØ¶Ø§Ø­Øª Ù†ÛÛŒÚº:

Ø®Ø¨Ø±: {text}

Ø§Ø¯Ø§Ø±Û’: {entity_list}
"""
    if lang == "Arabic":
        return f"""
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«.

Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø§Ø³ØªØ®Ø±Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„ÙƒØ§Ù…Ù„Ø©:
- subject (Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙÙ‚Ø·)
- action (Ø§Ù„ÙØ¹Ù„)
- object (Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ÙÙ‚Ø·)
- context (ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ© Ø¥Ù† ÙˆØ¬Ø¯Øª)

Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø¨Ù…ØµÙÙˆÙØ© JSONØŒ Ø¯ÙˆÙ† Ø´Ø±Ø­:

Ø§Ù„Ù†Øµ: {text}

Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª: {entity_list}
"""
    raise ValueError(f"Unsupported language: {lang}")


@st.cache_data
def extract_narrative(text: str, lang: str):
    pipes = load_ner_pipelines()
    ner_pipe = pipes[lang]

    def chunk_text(t, width=450):
        return textwrap.wrap(t, width)

    raw_entities = []
    if lang == "English":
        nlp = ner_pipe
        doc = nlp(text)
        raw_entities = [(ent.text, ent.label_) for ent in doc.ents]
    else:
        for chunk in chunk_text(text):
            for ent in ner_pipe(chunk):
                raw_entities.append((ent["word"], ent["entity_group"]))

    entities_dict: dict[str, list[str]] = {}
    for word, label in raw_entities:
        entities_dict.setdefault(label, []).append(word)
    # flatten into list of unique strings
    all_entities = list({w for lst in entities_dict.values() for w in lst})

    label_prompt = build_label_prompt(lang, text, all_entities)
    r1 = model.generate_content([{"text": label_prompt}]).text.strip()
    r1 = re.sub(r"^```json\s*|```$", "", r1, flags=re.MULTILINE)
    try:
        labeled = json.loads(r1)
    except json.JSONDecodeError:
        labeled = []
    if not isinstance(labeled, list):
        labeled = []
    labeled_map = {
        e.get("entity", ""): e.get("label", "")
        for e in labeled
        if isinstance(e, dict) and "entity" in e and "label" in e
    }

    narrative_prompt = build_narrative_prompt(lang, text, all_entities)
    r2 = model.generate_content([{"text": narrative_prompt}]).text.strip()
    r2 = re.sub(r"^```json\s*|```$", "", r2, flags=re.MULTILINE)
    try:
        events = json.loads(r2)
    except json.JSONDecodeError:
        events = []
    if not isinstance(events, list):
        events = []

    def find_role(name: str) -> str:
        return labeled_map.get(name, "Unknown")

    for ev in events:
        ev["subject_role"] = find_role(ev.get("subject", ""))
        ev["object_role"] = find_role(ev.get("object", ""))

    return entities_dict, labeled, events


st.set_page_config(page_title="Narrative Extraction Demo", layout="wide")
st.title("ğŸŒ Multilingual Narrative Extraction")

lang = st.selectbox("Choose language", ["English", "Hindi", "Urdu", "Arabic"])
text = st.text_area("Paste your article text here:", height=250)

if st.button("Extract Narrative"):
    if not text.strip():
        st.warning("Please paste some article text first.")
    else:
        with st.spinner("Running NER â†’ Role Labeling â†’ Extractionâ€¦"):
            entities_dict, labeled, events = extract_narrative(text, lang)
            time.sleep(0.5)

        st.subheader("ğŸ•µï¸ Named Entities")
        st.json(entities_dict)

        st.subheader("ğŸ·ï¸ Labeled Entities")
        st.json(labeled)

        st.subheader("ğŸ“– Extracted Events")
        st.json(events)
